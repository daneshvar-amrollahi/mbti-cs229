{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4_/8jk7rgt141nghfj9gsw4_thm0000gn/T/ipykernel_72936/370164429.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-02-17 15:25:13.397130: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Embedding, SpatialDropout1D, LSTM, GRU, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "# import LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_plots(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.savefig(string + '.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'posts', 'cleaned_posts'], dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('cleaned_dataset_1000.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(df['cleaned_posts'])\n",
    "tokenizer.word_index # Get our learned vocabulary\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "VOCAB_SIZE = len(word_index)+1 # Total words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(df['cleaned_posts'])\n",
    "MAX_SEQ_LENGTH = max(len(seq) for seq in X)\n",
    "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen= MAX_SEQ_LENGTH) # Pad the sequence to the same length to make it uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = LabelEncoder().fit_transform(df.type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3792, 892), (3792,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state=42, k_neighbors=1)\n",
    "X_res, y_res = smote.fit_resample(X,labels)\n",
    "X_res.shape, y_res.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Exception in thread Thread-20:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "Exception in thread Thread-21:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "Exception in thread Thread-22:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "Thread-19:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 980, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    self.run()\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    self.run()\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    self.run()\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/ipykernel/ipkernel.py\", line 761, in run_closure\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 917, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 917, in run\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 1166, in _worker_loop\n",
      "    _threading_Thread_run(self)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/threading.py\", line 917, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 1166, in _worker_loop\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 1166, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 957, in _do_train_job\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 957, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 638, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 1166, in _worker_loop\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 957, in _do_train_job\n",
      "    tally, raw_tally = self._do_train_job(data_iterable, alpha, thread_private_mem)\n",
      "  File \"/Users/zainanasalma/opt/anaconda3/envs/cs229/lib/python3.9/site-packages/gensim/models/word2vec.py\", line 957, in _do_train_job\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 638, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 638, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "    tally += train_batch_cbow(self, sentences, alpha, work, neu1, self.compute_loss)\n",
      "  File \"gensim/models/word2vec_inner.pyx\", line 638, in gensim.models.word2vec_inner.train_batch_cbow\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "ValueErrorValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      ": The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n",
      "ValueError: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()\n"
     ]
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(X_res, vector_size=100, window=5, min_count=1, workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word2vec_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/Users/zainanasalma/Desktop/stanford/courses/CS229/mbti-cs229/Word2vec_model.model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mword2vec_model\u001b[49m\u001b[38;5;241m.\u001b[39msave(model_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'word2vec_model' is not defined"
     ]
    }
   ],
   "source": [
    "model_path = \"/Users/zainanasalma/Desktop/stanford/courses/CS229/mbti-cs229/Word2vec_model.model\"\n",
    "word2vec_model.save(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 100\n",
    "embedding_matrix = np.zeros((VOCAB_SIZE, embedding_size))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in word2vec_model.wv:\n",
    "        embedding_vector = word2vec_model.wv[word]\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_one_hot = pd.get_dummies(y_res)\n",
    "n_classes = y_one_hot.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_one_hot, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate = 0.1\n",
    "model = Sequential()\n",
    "best_model.add(Embedding(VOCAB_SIZE, embedding_size, input_length=MAX_SEQ_LENGTH, weights=[embedding_matrix], trainable=False))\n",
    "best_model.add(SimpleRNN(100))\n",
    "best_model.add(Dropout(rate))\n",
    "best_model.add(Dense(n_classes, activation='softmax'))\n",
    "best_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs229",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
